{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl_to_list(filepath):\n",
    "    data_list = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            data_list.append(json.loads(line))\n",
    "    return data_list\n",
    "\n",
    "# 사용 예시\n",
    "filepath = 'counterfact_memit.jsonl'\n",
    "data = load_jsonl_to_list(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_id': 0,\n",
       " 'pararel_idx': 2796,\n",
       " 'requested_rewrite': {'prompt': 'The mother tongue of {} is',\n",
       "  'relation_id': 'P103',\n",
       "  'target_new': {'str': 'English', 'id': 'Q1860'},\n",
       "  'target_true': {'str': 'French', 'id': 'Q150'},\n",
       "  'subject': 'Danielle Darrieux'},\n",
       " 'paraphrase_prompts': ['Shayna does this and Yossel goes still and dies. Danielle Darrieux, a native',\n",
       "  'An album was recorded for Capitol Nashville but never released. Danielle Darrieux spoke the language'],\n",
       " 'neighborhood_prompts': ['The mother tongue of Léon Blum is',\n",
       "  'The native language of Montesquieu is',\n",
       "  'François Bayrou, a native',\n",
       "  'The native language of Raymond Barre is',\n",
       "  'Michel Rocard is a native speaker of',\n",
       "  'Jacques Chaban-Delmas is a native speaker of',\n",
       "  'The native language of François Bayrou is',\n",
       "  'Maurice Genevoix, speaker of',\n",
       "  'The mother tongue of François Bayrou is',\n",
       "  'Melchior de Vogüé, speaker of'],\n",
       " 'attribute_prompts': ['J.\\xa0R.\\xa0R. Tolkien is a native speaker of',\n",
       "  'The mother tongue of Douglas Adams is',\n",
       "  'The mother tongue of Paul McCartney is',\n",
       "  'Elvis Presley is a native speaker of',\n",
       "  'Barack Obama, speaker of',\n",
       "  'Douglas Adams, speaker of',\n",
       "  'Meryl Streep, a native',\n",
       "  'George Orwell spoke the language',\n",
       "  'George Washington, a native',\n",
       "  'Michael Jackson, a native'],\n",
       " 'generation_prompts': [\"Danielle Darrieux's mother tongue is\",\n",
       "  'Where Danielle Darrieux is from, people speak the language of',\n",
       "  \"Danielle Darrieux's mother tongue is\",\n",
       "  'Danielle Darrieux was born in',\n",
       "  \"Danielle Darrieux's mother tongue is\",\n",
       "  \"Danielle Darrieux's mother tongue is\",\n",
       "  'Danielle Darrieux was born in',\n",
       "  'Where Danielle Darrieux is from, people speak the language of',\n",
       "  'Danielle Darrieux was born in',\n",
       "  'Danielle Darrieux was born in']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English label for P103 is: native language\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikidata_label(property_id):\n",
    "    # SPARQL 쿼리 엔드포인트\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    # SPARQL 쿼리 (입력받은 property_id에 해당하는 속성의 영어 레이블을 가져옴)\n",
    "    query = f\"\"\"\n",
    "    SELECT ?label WHERE {{\n",
    "      wd:{property_id} rdfs:label ?label.\n",
    "      FILTER(LANG(?label) = \"en\")\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # 요청 헤더\n",
    "    headers = {\n",
    "        \"Accept\": \"application/sparql-results+json\"\n",
    "    }\n",
    "\n",
    "    # 요청 전송\n",
    "    response = requests.get(url, headers=headers, params={'query': query})\n",
    "\n",
    "    # 결과를 JSON으로 변환\n",
    "    data = response.json()\n",
    "\n",
    "    # 영어 레이블 반환\n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['label']['value']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 예시 사용\n",
    "property_id = \"P103\"\n",
    "label = get_wikidata_label(property_id)\n",
    "print(f\"The English label for {property_id} is: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P103'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['requested_rewrite']['relation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_list = []\n",
    "for i in range(len(data)):\n",
    "    property_id = data[i]['requested_rewrite']['relation_id']\n",
    "    rel_list.append(property_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "rel_list = list(set(rel_list))\n",
    "\n",
    "print(len(rel_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English label for P138 is: named after\n",
      "The English label for P641 is: sport\n",
      "The English label for P37 is: official language\n",
      "The English label for P27 is: country of citizenship\n",
      "The English label for P495 is: country of origin\n",
      "The English label for P19 is: place of birth\n",
      "The English label for P413 is: position played on team / speciality\n",
      "The English label for P101 is: field of work\n",
      "The English label for P264 is: record label\n",
      "The English label for P740 is: location of formation\n",
      "The English label for P39 is: position held\n",
      "The English label for P159 is: headquarters location\n",
      "The English label for P449 is: original broadcaster\n",
      "The English label for P364 is: original language of film or TV show\n",
      "The English label for P30 is: continent\n",
      "The English label for P463 is: member of\n",
      "The English label for P1412 is: languages spoken, written or signed\n",
      "The English label for P140 is: religion or worldview\n",
      "The English label for P127 is: owned by\n",
      "The English label for P131 is: located in the administrative territorial entity\n",
      "The English label for P108 is: employer\n",
      "The English label for P136 is: genre\n",
      "The English label for P36 is: capital\n",
      "The English label for P176 is: manufacturer\n",
      "The English label for P20 is: place of death\n",
      "The English label for P276 is: location\n",
      "The English label for P190 is: twinned administrative body\n",
      "The English label for P937 is: work location\n",
      "The English label for P103 is: native language\n",
      "The English label for P106 is: occupation\n",
      "The English label for P1303 is: instrument\n",
      "The English label for P407 is: language of work or name\n",
      "The English label for P178 is: developer\n",
      "The English label for P17 is: country\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "new_list = []\n",
    "for property_id in rel_list:\n",
    "    label = get_wikidata_label(property_id)\n",
    "    print(f\"The English label for {property_id} is: {label}\")\n",
    "    new_list.append(label)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['named after',\n",
       " 'sport',\n",
       " 'official language',\n",
       " 'country of citizenship',\n",
       " 'country of origin',\n",
       " 'place of birth',\n",
       " 'position played on team / speciality',\n",
       " 'field of work',\n",
       " 'record label',\n",
       " 'location of formation',\n",
       " 'position held',\n",
       " 'headquarters location',\n",
       " 'original broadcaster',\n",
       " 'original language of film or TV show',\n",
       " 'continent',\n",
       " 'member of',\n",
       " 'languages spoken, written or signed',\n",
       " 'religion or worldview',\n",
       " 'owned by',\n",
       " 'located in the administrative territorial entity',\n",
       " 'employer',\n",
       " 'genre',\n",
       " 'capital',\n",
       " 'manufacturer',\n",
       " 'place of death',\n",
       " 'location',\n",
       " 'twinned administrative body',\n",
       " 'work location',\n",
       " 'native language',\n",
       " 'occupation',\n",
       " 'instrument',\n",
       " 'language of work or name',\n",
       " 'developer',\n",
       " 'country']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P138,P641,P37,P27,P495,P19,P413,P101,P264,P740,P39,P159,P449,P364,P30,P463,P1412,P140,P127,P131,P108,P136,P36,P176,P20,P276,P190,P937,P103,P106,P1303,P407,P178,P17,"
     ]
    }
   ],
   "source": [
    "for i in rel_list:\n",
    "    print(i, end = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_list_to_jsonl(data_list, filepath):\n",
    "    with open(filepath, 'w') as file:\n",
    "        for item in data_list:\n",
    "            file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# 사용 예시\n",
    "\n",
    "filepath = 'rel_list.jsonl'\n",
    "save_list_to_jsonl(rel_list, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English labels for Q265852 are: ['English', 'computer scientist', 'businessperson', 'Apple', 'manager', 'engineer', 'Mobile', 'chief executive officer', 'presenter', 'United States of America']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikidata_labels(entity_id):\n",
    "    # SPARQL 쿼리 엔드포인트\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    # SPARQL 쿼리 (입력받은 entity_id에 해당하는 값들의 영어 레이블을 가져옴)\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT ?valueLabel WHERE {{\n",
    "      wd:{entity_id} ?relation ?value.\n",
    "      VALUES ?relation {{\n",
    "        wdt:P138 wdt:P641 wdt:P37 wdt:P27 wdt:P495 wdt:P19 wdt:P413 wdt:P101\n",
    "        wdt:P264 wdt:P740 wdt:P39 wdt:P159 wdt:P449 wdt:P364 wdt:P30 wdt:P463\n",
    "        wdt:P1412 wdt:P140 wdt:P127 wdt:P131 wdt:P108 wdt:P136 wdt:P36 wdt:P176\n",
    "        wdt:P20 wdt:P276 wdt:P190 wdt:P937 wdt:P103 wdt:P106 wdt:P1303 wdt:P407\n",
    "        wdt:P178 wdt:P17\n",
    "      }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    # 요청 헤더\n",
    "    headers = {\n",
    "        \"Accept\": \"application/sparql-results+json\"\n",
    "    }\n",
    "\n",
    "    # 요청 전송\n",
    "    response = requests.get(url, headers=headers, params={'query': query})\n",
    "\n",
    "    # 결과를 JSON으로 변환\n",
    "    data = response.json()\n",
    "\n",
    "    # 영어 레이블 반환\n",
    "    if data['results']['bindings']:\n",
    "        return [result['valueLabel']['value'] for result in data['results']['bindings']]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# 예시 사용\n",
    "entity_id = \"Q265852\"\n",
    "labels = get_wikidata_labels(entity_id)\n",
    "print(f\"The English labels for {entity_id} are: {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English labels for entity ID Q265852 are: ['English', 'computer scientist', 'businessperson', 'Apple', 'manager', 'engineer', 'Mobile', 'chief executive officer', 'presenter', 'United States of America']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def search_entity_id(search_string):\n",
    "    # SPARQL 쿼리 엔드포인트\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    # SPARQL 검색 쿼리 (입력받은 search_string에 해당하는 엔티티의 ID를 찾음)\n",
    "    query = f\"\"\"\n",
    "    SELECT ?item WHERE {{\n",
    "      ?item rdfs:label \"{search_string}\"@en.\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    # 요청 헤더\n",
    "    headers = {\n",
    "        \"Accept\": \"application/sparql-results+json\"\n",
    "    }\n",
    "\n",
    "    # 요청 전송\n",
    "    response = requests.get(url, headers=headers, params={'query': query})\n",
    "\n",
    "    # 결과를 JSON으로 변환\n",
    "    data = response.json()\n",
    "\n",
    "    # 첫 번째 결과에서 엔티티 ID 반환\n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['item']['value'].split('/')[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_wikidata_labels(entity_id):\n",
    "    # SPARQL 쿼리 엔드포인트\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    # SPARQL 쿼리 (입력받은 entity_id에 해당하는 값들의 영어 레이블을 가져옴)\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT ?valueLabel WHERE {{\n",
    "      wd:{entity_id} ?relation ?value.\n",
    "      VALUES ?relation {{\n",
    "        wdt:P138 wdt:P641 wdt:P37 wdt:P27 wdt:P495 wdt:P19 wdt:P413 wdt:P101\n",
    "        wdt:P264 wdt:P740 wdt:P39 wdt:P159 wdt:P449 wdt:P364 wdt:P30 wdt:P463\n",
    "        wdt:P1412 wdt:P140 wdt:P127 wdt:P131 wdt:P108 wdt:P136 wdt:P36 wdt:P176\n",
    "        wdt:P20 wdt:P276 wdt:P190 wdt:P937 wdt:P103 wdt:P106 wdt:P1303 wdt:P407\n",
    "        wdt:P178 wdt:P17\n",
    "      }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    # 요청 헤더\n",
    "    headers = {\n",
    "        \"Accept\": \"application/sparql-results+json\"\n",
    "    }\n",
    "\n",
    "    # 요청 전송\n",
    "    response = requests.get(url, headers=headers, params={'query': query})\n",
    "\n",
    "    # 결과를 JSON으로 변환\n",
    "    data = response.json()\n",
    "\n",
    "    # 영어 레이블 반환\n",
    "    if data['results']['bindings']:\n",
    "        return [result['valueLabel']['value'] for result in data['results']['bindings']]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def main(search_string):\n",
    "    entity_id = search_entity_id(search_string)\n",
    "    if entity_id:\n",
    "        labels = get_wikidata_labels(entity_id)\n",
    "        print(f\"The English labels for entity ID {entity_id} are: {labels}\")\n",
    "    else:\n",
    "        print(f\"No entity found for search string '{search_string}'.\")\n",
    "\n",
    "# 예시 사용\n",
    "search_string = \"Tim Cook\"\n",
    "main(search_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
