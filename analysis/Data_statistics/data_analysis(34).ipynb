{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sbj = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_sbj.xlsx')\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 모든 값을 문자열로 변환\n",
    "df_sbj['one_hop'] = df_sbj['one_hop'].fillna('').astype(str)\n",
    "\n",
    "# 각 one_hop에 대해 단어 개수를 계산\n",
    "df_sbj['word_count'] = df_sbj['one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "\n",
    "# 히스토그램 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts, bins, patches = plt.hist(df_sbj['word_count'], bins=range(0, df_sbj['word_count'].max() + 2), alpha=0.7, edgecolor='black')\n",
    "\n",
    "# 각 막대 위에 빈도수 레이블 추가\n",
    "for count, x in zip(counts, bins[:-1]):\n",
    "    if count > 0:\n",
    "        plt.text(x + 0.4, count, str(int(count)), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 그래프 레이블 설정\n",
    "plt.title('Subject count')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n",
    "\n",
    "# 특정 기준 값들에 대해 개수와 비율을 계산하는 함수 정의\n",
    "def count_and_ratio(df, column, thresholds):\n",
    "    total_count = len(df)\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        count = df[column][df[column] < threshold].count()\n",
    "        ratio = (count / total_count) * 100\n",
    "        results.append(f\"Count smaller than {threshold}: {count}({ratio:.2f}%)\")\n",
    "    return results\n",
    "\n",
    "# 기준 값 리스트\n",
    "thresholds = [1, 3, 5, 10]\n",
    "\n",
    "# 결과 출력\n",
    "results = count_and_ratio(df_sbj, 'word_count', thresholds)\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_obj_true = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_obj_true.xlsx')\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 모든 값을 문자열로 변환\n",
    "df_obj_true['obj_one_hop'] = df_obj_true['obj_one_hop'].fillna('').astype(str)\n",
    "\n",
    "# 각 one_hop에 대해 단어 개수를 계산\n",
    "df_obj_true['word_count'] = df_obj_true['obj_one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "\n",
    "# 히스토그램 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts, bins, patches = plt.hist(df_obj_true['word_count'], bins=range(0, df_obj_true['word_count'].max() + 2), alpha=0.7, edgecolor='black')\n",
    "\n",
    "# 각 막대 위에 빈도수 레이블 추가\n",
    "for count, x in zip(counts, bins[:-1]):\n",
    "    if count > 0:\n",
    "        plt.text(x + 0.4, count, str(int(count)), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 그래프 레이블 설정\n",
    "plt.title('Object True count')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n",
    "\n",
    "# 특정 기준 값들에 대해 개수와 비율을 계산하는 함수 정의\n",
    "def count_and_ratio(df, column, thresholds):\n",
    "    total_count = len(df)\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        count = df[column][df[column] < threshold].count()\n",
    "        ratio = (count / total_count) * 100\n",
    "        results.append(f\"Count smaller than {threshold}: {count}({ratio:.2f}%)\")\n",
    "    return results\n",
    "\n",
    "# 기준 값 리스트\n",
    "thresholds = [1, 3, 5, 10]\n",
    "\n",
    "# 결과 출력\n",
    "results = count_and_ratio(df_obj_true, 'word_count', thresholds)\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_obj_new = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_obj_new.xlsx')\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 모든 값을 문자열로 변환\n",
    "df_obj_new['obj_new_one_hop'] = df_obj_new['obj_new_one_hop'].fillna('').astype(str)\n",
    "\n",
    "# 각 one_hop에 대해 단어 개수를 계산\n",
    "df_obj_new['word_count'] = df_obj_new['obj_new_one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "\n",
    "# 히스토그램 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts, bins, patches = plt.hist(df_obj_new['word_count'], bins=range(0, df_obj_new['word_count'].max() + 2), alpha=0.7, edgecolor='black')\n",
    "\n",
    "# 각 막대 위에 빈도수 레이블 추가\n",
    "for count, x in zip(counts, bins[:-1]):\n",
    "    if count > 0:\n",
    "        plt.text(x + 0.4, count, str(int(count)), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 그래프 레이블 설정\n",
    "plt.title('Object New count')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n",
    "\n",
    "# 특정 기준 값들에 대해 개수와 비율을 계산하는 함수 정의\n",
    "def count_and_ratio(df, column, thresholds):\n",
    "    total_count = len(df)\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        count = df[column][df[column] < threshold].count()\n",
    "        ratio = (count / total_count) * 100\n",
    "        results.append(f\"Count smaller than {threshold}: {count}({ratio:.2f}%)\")\n",
    "    return results\n",
    "\n",
    "# 기준 값 리스트\n",
    "thresholds = [1, 3, 5, 10]\n",
    "\n",
    "# 결과 출력\n",
    "results = count_and_ratio(df_obj_new, 'word_count', thresholds)\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 모든 값을 문자열로 변환\n",
    "df_sbj['one_hop'] = df_sbj['one_hop'].fillna('').astype(str)\n",
    "df_obj_true['obj_one_hop'] = df_obj_true['obj_one_hop'].fillna('').astype(str)\n",
    "df_obj_new['obj_new_one_hop'] = df_obj_new['obj_new_one_hop'].fillna('').astype(str)\n",
    "\n",
    "# 각 one_hop에 대해 단어 개수를 계산x\n",
    "df_sbj['word_count'] = df_sbj['one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "df_obj_true['word_count'] = df_obj_true['obj_one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "df_obj_new['word_count'] = df_obj_new['obj_new_one_hop'].apply(lambda x: 0 if x == '' else len(x.split(',')))\n",
    "\n",
    "# 단어 개수를 하나의 배열로 결합\n",
    "combined_counts = df_sbj['word_count'] + df_obj_true['word_count'] + df_obj_new['word_count']\n",
    "\n",
    "# 히스토그램 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(combined_counts, bins=range(0, combined_counts.max() + 2), alpha=0.5, edgecolor='black')\n",
    "\n",
    "# 각 막대 위에 빈도수 레이블 추가\n",
    "counts, bins = np.histogram(combined_counts, bins=range(0, combined_counts.max() + 2))\n",
    "for count, x in zip(counts, bins[:-1]):\n",
    "    if count > 0:\n",
    "        plt.text(x + 0.4, count, str(int(count)), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 그래프에 레이블 추가\n",
    "plt.title('Total Count')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n",
    "\n",
    "# 특정 기준 값들에 대해 개수와 비율을 계산하는 함수 정의\n",
    "def count_and_ratio(series, thresholds):\n",
    "    total_count = len(series)\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        count = (series < threshold).sum()  # < threshold에 해당하는 개수 계산\n",
    "        ratio = (count / total_count) * 100\n",
    "        results.append(f\"Count smaller than {threshold}: {count} ({ratio:.2f}%)\")\n",
    "    return results\n",
    "\n",
    "# 기준 값 리스트\n",
    "thresholds = [1, 3, 5, 10]\n",
    "\n",
    "# 결과 출력\n",
    "results = count_and_ratio(combined_counts, thresholds)\n",
    "\n",
    "# 결과 출력\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gyubin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyubin/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/home/gyubin/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/IPython/core/magics/osm.py:428: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_sbj = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_sbj.xlsx')\n",
    "df_obj_true = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_obj_true.xlsx')\n",
    "df_obj_new = pd.read_excel('./Knowledge_Editing_Dataset/data/one_hop/one_hop_obj_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gyubin/Knowledge_Editing_Dataset/data/one_hop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyubin/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd Knowledge_Editing_Dataset/data/one_hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>one_hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Danielle Darrieux</td>\n",
       "      <td>Q234149</td>\n",
       "      <td>singer,actor,Bois-le-Roi,film,film actor,Franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Edwin of Northumbria</td>\n",
       "      <td>Q348955</td>\n",
       "      <td>Kingdom of Bernicia,English,King of Northumbri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Toko Yasuda</td>\n",
       "      <td>Q7813654</td>\n",
       "      <td>rock music,Blonde Redhead,musician,bass guitar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Autonomous University of Madrid</td>\n",
       "      <td>Q788091</td>\n",
       "      <td>Coalition for Advancing Research Assessment,Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Q6709677</td>\n",
       "      <td>United States of America,Oakland County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Thomas Joannes Stieltjes</td>\n",
       "      <td>Q510916</td>\n",
       "      <td>Kingdom of the Netherlands,Toulouse,mathematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Anaal Nathrakh</td>\n",
       "      <td>Q483140</td>\n",
       "      <td>black metal,Earache Records,Season of Mist,Bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Apple A5</td>\n",
       "      <td>Q420764</td>\n",
       "      <td>Apple,Samsung Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>Q23661</td>\n",
       "      <td>New Zealand,Oceania,Arthur Wellesley, 1st Duke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Shree Pundalik</td>\n",
       "      <td>Q7503512</td>\n",
       "      <td>silent film,British Raj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                          subject subject_id  \\\n",
       "0           0      0                Danielle Darrieux    Q234149   \n",
       "1           1      1             Edwin of Northumbria    Q348955   \n",
       "2           2      2                      Toko Yasuda   Q7813654   \n",
       "3           3      3  Autonomous University of Madrid    Q788091   \n",
       "4           4      4                             Lyon   Q6709677   \n",
       "5           5      5         Thomas Joannes Stieltjes    Q510916   \n",
       "6           6      6                   Anaal Nathrakh    Q483140   \n",
       "7           7      7                         Apple A5    Q420764   \n",
       "8           8      8                       Wellington     Q23661   \n",
       "9           9      9                   Shree Pundalik   Q7503512   \n",
       "\n",
       "                                             one_hop  \n",
       "0  singer,actor,Bois-le-Roi,film,film actor,Franc...  \n",
       "1  Kingdom of Bernicia,English,King of Northumbri...  \n",
       "2  rock music,Blonde Redhead,musician,bass guitar...  \n",
       "3  Coalition for Advancing Research Assessment,Co...  \n",
       "4            United States of America,Oakland County  \n",
       "5  Kingdom of the Netherlands,Toulouse,mathematic...  \n",
       "6  black metal,Earache Records,Season of Mist,Bac...  \n",
       "7                          Apple,Samsung Electronics  \n",
       "8  New Zealand,Oceania,Arthur Wellesley, 1st Duke...  \n",
       "9                            silent film,British Raj  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sbj.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency_sbj = []\n",
    "for i in range(len(df_sbj)):\n",
    "    try:\n",
    "        for word in (df_sbj.loc[i, 'one_hop'].split(',')):\n",
    "            frequency_sbj.append(word)\n",
    "    except:\n",
    "        pass\n",
    "counter_sbj = Counter(frequency_sbj)\n",
    "with open(\"subject_one_hop_frequency.txt\", 'w') as f:\n",
    "    for key, value in counter_sbj.most_common():\n",
    "        f.write(f'{key}: {value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>obj</th>\n",
       "      <th>obj_id</th>\n",
       "      <th>obj_one_hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>Q150</td>\n",
       "      <td>Bailiwick of Guernsey,Belgium,Vanuatu,Laos,Mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Christianity</td>\n",
       "      <td>Q5043</td>\n",
       "      <td>Jerusalem,Christ,Jesus,Nazareth,worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>guitar</td>\n",
       "      <td>Q6607</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Q29</td>\n",
       "      <td>Universal Postal Union,Organization for Securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Beirut</td>\n",
       "      <td>Q3820</td>\n",
       "      <td>Emirate of Dubai,Mexico City,Île-de-France,Tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Q7411</td>\n",
       "      <td>Kingdom of the Netherlands,Low Countries,Belgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Q2256</td>\n",
       "      <td>Chicago,English,Xi'an,Guangzhou,Johannesburg,L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Q312</td>\n",
       "      <td>apple,Los Altos,United States of America,The V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Q3130</td>\n",
       "      <td>Thomas Townshend, 1st Viscount Sydney,Australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>India</td>\n",
       "      <td>Q668</td>\n",
       "      <td>Universal Postal Union,Shanghai Cooperation Or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           obj obj_id  \\\n",
       "0      0        French   Q150   \n",
       "1      1  Christianity  Q5043   \n",
       "2      2        guitar  Q6607   \n",
       "3      3         Spain    Q29   \n",
       "4      4        Beirut  Q3820   \n",
       "5      5         Dutch  Q7411   \n",
       "6      6    Birmingham  Q2256   \n",
       "7      7         Apple   Q312   \n",
       "8      8        Sydney  Q3130   \n",
       "9      9         India   Q668   \n",
       "\n",
       "                                         obj_one_hop  \n",
       "0  Bailiwick of Guernsey,Belgium,Vanuatu,Laos,Mal...  \n",
       "1          Jerusalem,Christ,Jesus,Nazareth,worldwide  \n",
       "2                                                NaN  \n",
       "3  Universal Postal Union,Organization for Securi...  \n",
       "4  Emirate of Dubai,Mexico City,Île-de-France,Tri...  \n",
       "5  Kingdom of the Netherlands,Low Countries,Belgi...  \n",
       "6  Chicago,English,Xi'an,Guangzhou,Johannesburg,L...  \n",
       "7  apple,Los Altos,United States of America,The V...  \n",
       "8  Thomas Townshend, 1st Viscount Sydney,Australi...  \n",
       "9  Universal Postal Union,Shanghai Cooperation Or...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj_true.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency_obj = []\n",
    "for i in range(len(df_obj_true)):\n",
    "    try:\n",
    "        for word in (df_obj_true.loc[i, 'obj_one_hop'].split(',')):\n",
    "            frequency_obj.append(word)\n",
    "    except:\n",
    "        pass\n",
    "counter_obj = Counter(frequency_obj)\n",
    "with open(\"object_true_one_hop_frequency.txt\", 'w') as f:\n",
    "    for key, value in counter_obj.most_common():\n",
    "        f.write(f'{key}: {value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>obj</th>\n",
       "      <th>obj_id</th>\n",
       "      <th>obj_new_one_hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>Q1860</td>\n",
       "      <td>Bailiwick of Guernsey,British Virgin Islands,T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Q432</td>\n",
       "      <td>Masjid al-Haram,Muslim world,Arabic,Qibla,devo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>piano</td>\n",
       "      <td>Q5994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Q34</td>\n",
       "      <td>Universal Postal Union,Organization for Securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Manila</td>\n",
       "      <td>Q1461</td>\n",
       "      <td>Honolulu County,Maui County,Mexico City,Guangz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>English</td>\n",
       "      <td>Q1860</td>\n",
       "      <td>Bailiwick of Guernsey,British Virgin Islands,T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Q1345</td>\n",
       "      <td>Philadelphia County,Nizhny Novgorod,Salvador,F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Google</td>\n",
       "      <td>Q95</td>\n",
       "      <td>Society for Geoinformatics, GeoIT and Navigati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Q42448</td>\n",
       "      <td>Kitwe,English,Macerata,Donetsk,Sheffield,Pitts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Q34</td>\n",
       "      <td>Universal Postal Union,Organization for Securi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           obj  obj_id  \\\n",
       "0      0       English   Q1860   \n",
       "1      1         Islam    Q432   \n",
       "2      2         piano   Q5994   \n",
       "3      3        Sweden     Q34   \n",
       "4      4        Manila   Q1461   \n",
       "5      5       English   Q1860   \n",
       "6      6  Philadelphia   Q1345   \n",
       "7      7        Google     Q95   \n",
       "8      8     Sheffield  Q42448   \n",
       "9      9        Sweden     Q34   \n",
       "\n",
       "                                     obj_new_one_hop  \n",
       "0  Bailiwick of Guernsey,British Virgin Islands,T...  \n",
       "1  Masjid al-Haram,Muslim world,Arabic,Qibla,devo...  \n",
       "2                                                NaN  \n",
       "3  Universal Postal Union,Organization for Securi...  \n",
       "4  Honolulu County,Maui County,Mexico City,Guangz...  \n",
       "5  Bailiwick of Guernsey,British Virgin Islands,T...  \n",
       "6  Philadelphia County,Nizhny Novgorod,Salvador,F...  \n",
       "7  Society for Geoinformatics, GeoIT and Navigati...  \n",
       "8  Kitwe,English,Macerata,Donetsk,Sheffield,Pitts...  \n",
       "9  Universal Postal Union,Organization for Securi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency_obj_new = []\n",
    "for i in range(len(df_obj_new)):\n",
    "    try:\n",
    "        for word in (df_obj_new.loc[i, 'obj_new_one_hop'].split(',')):\n",
    "            frequency_obj_new.append(word)\n",
    "    except:\n",
    "        pass\n",
    "counter_obj_new = Counter(frequency_obj_new)\n",
    "with open(\"object_new_one_hop_frequency.txt\", 'w') as f:\n",
    "    for key, value in counter_obj_new.most_common():\n",
    "        f.write(f'{key}: {value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# def sort_one_hop(df,column,counter, idx, rank = 3):\n",
    "#     new_dict = dict()\n",
    "#     for word in (df.loc[idx, column].split(',')):\n",
    "#         new_dict[word] = counter[word]\n",
    "#         new_dict = dict(sorted(new_dict.items(), key = lambda item:item[1]))\n",
    "#         new_list = list(new_dict.keys())\n",
    "#     return len(new_list)\n",
    "# rank = 10\n",
    "# number=0\n",
    "# a=0\n",
    "# b=0\n",
    "# c=0\n",
    "# for i in tqdm(range(len(df_sbj))):\n",
    "#     idx = i\n",
    "#     rank = -1\n",
    "#     try:\n",
    "#         # print(1)\n",
    "#         a+=sort_one_hop(df_sbj, 'one_hop', counter_sbj, idx, rank)\n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         b+= sort_one_hop(df_obj_true, 'obj_one_hop', counter_sbj, idx, rank)\n",
    "#     except:\n",
    "#         pass\n",
    "#     try:\n",
    "#         c+=sort_one_hop(df_obj_new, 'obj_new_one_hop', counter_sbj, idx, rank)            \n",
    "#     except:\n",
    "#         pass\n",
    "# print(a, b, c)\n",
    "# print(a+b+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hispania',\n",
       " 'member states of the Organization of Ibero-American States',\n",
       " 'Organization of Ibero-American States',\n",
       " 'Central American Bank for Economic Integration',\n",
       " 'United Nations Security Council',\n",
       " 'Spanish',\n",
       " 'Spain',\n",
       " 'Madrid',\n",
       " 'Organisation for Joint Armament Cooperation',\n",
       " 'European Air Transport Command',\n",
       " 'League of Nations',\n",
       " 'European Southern Observatory',\n",
       " 'European Union',\n",
       " 'European Space Agency',\n",
       " 'Schengen Area',\n",
       " 'Movement Coordination Centre Europe',\n",
       " 'Council of Europe',\n",
       " 'Eurocontrol',\n",
       " 'NATO',\n",
       " 'Treaty on Open Skies']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_one_hop(df,column,counter, idx, rank = 3):\n",
    "    new_dict = dict()\n",
    "    for word in (df.loc[idx, column].split(',')):\n",
    "        new_dict[word] = counter[word]\n",
    "        new_dict = dict(sorted(new_dict.items(), key = lambda item:item[1]))\n",
    "        new_list = list(new_dict.keys())\n",
    "    return new_list[:rank]\n",
    "rank = 20\n",
    "sort_one_hop(df_obj_true, 'obj_one_hop', counter_obj, 3, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2101\n",
      "21919\n"
     ]
    }
   ],
   "source": [
    "def sort_one_hop(df,column,counter, idx, rank = 3):\n",
    "    new_dict = dict()\n",
    "    for word in (df.loc[idx, column].split(',')):\n",
    "        new_dict[word] = counter[word]\n",
    "        new_dict = dict(sorted(new_dict.items(), key = lambda item:item[1]))\n",
    "        new_list = list(new_dict.keys())\n",
    "    return new_list[:rank]\n",
    "\n",
    "full10_list = []\n",
    "for i in range(len(df_sbj)):\n",
    "    idx = i\n",
    "    rank = 10\n",
    "    try:\n",
    "        z= sort_one_hop(df_sbj, 'one_hop', counter_sbj, idx, rank)\n",
    "        x= sort_one_hop(df_obj_true, 'obj_one_hop', counter_obj, idx, rank)\n",
    "        c =sort_one_hop(df_obj_new, 'obj_new_one_hop', counter_obj_new, idx, rank)\n",
    "        if len(z)+len(x)+len(c) == rank*3:\n",
    "            full10_list.append([idx, z, x, c])\n",
    "\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        x= sort_one_hop(df_obj_true, 'obj_one_hop', counter_sbj, idx, rank)\n",
    "print(len(full10_list))\n",
    "print(len(df_sbj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bois-le-Roi', 'Bordeaux', 'film', 'theatre', 'stage actor', 'singer', 'voice', 'film actor', 'actor', 'France']\n",
      "['Bois-le-Roi', 'film', 'stage actor', 'voice', 'actor']\n",
      "['Bordeaux', 'theatre', 'singer', 'film actor', 'France']\n"
     ]
    }
   ],
   "source": [
    "print(full10_list[0][1])\n",
    "sbj_train = [full10_list[0][1][i] for i in [0,2,4,6,8]]\n",
    "sbj_test = [full10_list[0][1][i] for i in [1,3,5,7,9]]\n",
    "print(sbj_train)\n",
    "print(sbj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gyubin/Knowledge_Editing_Dataset/EasyEdit/data/counterfact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyubin/anaconda3/envs/EasyEdit/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../EasyEdit/data/counterfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "1919\n",
      "21919\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path1 = 'counterfact-edit.json'\n",
    "file_path2 = 'counterfact-train.json'\n",
    "file_path3 = 'counterfact-val.json'\n",
    "\n",
    "with open(file_path1, 'r') as file:\n",
    "    data1 = json.load(file)\n",
    "    print(len(data1))\n",
    "with open(file_path2, 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "    print(len(data2))\n",
    "with open(file_path3, 'r') as file:\n",
    "    data3 = json.load(file)\n",
    "    print(len(data3))\n",
    "full_data = data1 + data2 + data3\n",
    "print(len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_full_data = sorted(full_data, key=lambda x: x['case_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for data in full10_list:\n",
    "    idx = data[0]\n",
    "    tup = sorted_full_data[idx]\n",
    "    tup['sbj_hop_train'] = [data[1][i]for i in [0,2,4,6,8]]\n",
    "    tup['sbj_hop_test'] = [data[1][i]for i in [1,3,5,7,9]]\n",
    "    tup['obj_true_hop_train'] = [data[2][i]for i in [0,2,4,6,8]]\n",
    "    tup['obj_true_hop_test'] = [data[2][i]for i in [1,3,5,7,9]]\n",
    "    tup['obj_new_hop_train'] = [data[3][i]for i in [0,2,4,6,8]]\n",
    "    tup['obj_new_hop_test'] = [data[3][i]for i in [1,3,5,7,9]]\n",
    "    answer.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'case_id': 0,\n",
       "  'prompt': 'The mother tongue of Danielle Darrieux is',\n",
       "  'target_new': 'English',\n",
       "  'subject': 'Danielle Darrieux',\n",
       "  'ground_truth': 'French',\n",
       "  'rephrase_prompt': 'Where Danielle Darrieux is from, people speak the language of',\n",
       "  'locality_prompt': 'Michel Rocard is a native speaker of',\n",
       "  'locality_ground_truth': 'French',\n",
       "  'sbj_hop_train': ['Bois-le-Roi', 'film', 'stage actor', 'voice', 'actor'],\n",
       "  'sbj_hop_test': ['Bordeaux', 'theatre', 'singer', 'film actor', 'France'],\n",
       "  'obj_true_hop_train': ['Overseas France',\n",
       "   'Mauritania',\n",
       "   'Andorra',\n",
       "   'Jersey',\n",
       "   'Burkina Faso'],\n",
       "  'obj_true_hop_test': ['Togo', 'Vanuatu', 'Ivory Coast', 'Chad', 'Gabon'],\n",
       "  'obj_new_hop_train': ['British Virgin Islands',\n",
       "   'United States Virgin Islands',\n",
       "   ' Ascension and Tristan da Cunha',\n",
       "   'British Indian Ocean Territory',\n",
       "   'Sint Maarten'],\n",
       "  'obj_new_hop_test': ['Turks and Caicos Islands',\n",
       "   'Saint Helena',\n",
       "   'Montserrat',\n",
       "   'Saint-Martin',\n",
       "   'Anguilla']},\n",
       " {'case_id': 3,\n",
       "  'prompt': 'Autonomous University of Madrid, which is located in',\n",
       "  'target_new': 'Sweden',\n",
       "  'subject': 'Autonomous University of Madrid',\n",
       "  'ground_truth': 'Spain',\n",
       "  'rephrase_prompt': 'and Sallie Beavers Riley. Autonomous University of Madrid is located in',\n",
       "  'locality_prompt': 'Biure, which is located in',\n",
       "  'locality_ground_truth': 'Spain',\n",
       "  'sbj_hop_train': ['YERUN',\n",
       "   'European Alliance for Social Sciences and Humanities',\n",
       "   'Spanish Association of University Presses',\n",
       "   'Agence universitaire de la Francophonie',\n",
       "   'Madrid'],\n",
       "  'sbj_hop_test': ['Alliance 4 Universities',\n",
       "   'Conference of Rectors of Spanish Universities',\n",
       "   'Coalition for Advancing Research Assessment',\n",
       "   'European University Association',\n",
       "   'Spain'],\n",
       "  'obj_true_hop_train': ['member states of the Organization of Ibero-American States',\n",
       "   'Hispania',\n",
       "   'Organisation for Joint Armament Cooperation',\n",
       "   'United Nations Security Council',\n",
       "   'European Southern Observatory'],\n",
       "  'obj_true_hop_test': ['Organization of Ibero-American States',\n",
       "   'Central American Bank for Economic Integration',\n",
       "   'European Air Transport Command',\n",
       "   'League of Nations',\n",
       "   'European Space Agency'],\n",
       "  'obj_new_hop_train': ['Kalmar Union',\n",
       "   'Union between Sweden and Norway',\n",
       "   'Barents Euro-Arctic Council',\n",
       "   'Council of the Baltic Sea States',\n",
       "   'European Free Trade Association'],\n",
       "  'obj_new_hop_test': ['Swedes',\n",
       "   'Partnership for Peace',\n",
       "   'Nordic Council',\n",
       "   'Nordic Battle Group',\n",
       "   'European Payments Union']},\n",
       " {'case_id': 5,\n",
       "  'prompt': 'The mother tongue of Thomas Joannes Stieltjes is',\n",
       "  'target_new': 'English',\n",
       "  'subject': 'Thomas Joannes Stieltjes',\n",
       "  'ground_truth': 'Dutch',\n",
       "  'rephrase_prompt': 'Thomas Joannes Stieltjes was born in',\n",
       "  'locality_prompt': 'Arend Lijphart is a native speaker of',\n",
       "  'locality_ground_truth': 'Dutch',\n",
       "  'sbj_hop_train': ['Faculté des sciences de Toulouse',\n",
       "   'Delft University of Technology',\n",
       "   'Royal Netherlands Academy of Arts and Sciences',\n",
       "   'Kingdom of the Netherlands',\n",
       "   'Dutch'],\n",
       "  'sbj_hop_test': ['Zwolle',\n",
       "   'Toulouse',\n",
       "   'Russian Academy of Sciences',\n",
       "   'mathematician',\n",
       "   'university teacher'],\n",
       "  'obj_true_hop_train': ['Low Countries',\n",
       "   'Sint Maarten',\n",
       "   'theodisk',\n",
       "   'Suriname',\n",
       "   'Netherlands'],\n",
       "  'obj_true_hop_test': ['Curaçao',\n",
       "   'Caribbean Netherlands',\n",
       "   'Aruba',\n",
       "   'Kingdom of the Netherlands',\n",
       "   'Belgium'],\n",
       "  'obj_new_hop_train': ['British Virgin Islands',\n",
       "   'United States Virgin Islands',\n",
       "   ' Ascension and Tristan da Cunha',\n",
       "   'British Indian Ocean Territory',\n",
       "   'Sint Maarten'],\n",
       "  'obj_new_hop_test': ['Turks and Caicos Islands',\n",
       "   'Saint Helena',\n",
       "   'Montserrat',\n",
       "   'Saint-Martin',\n",
       "   'Anguilla']},\n",
       " {'case_id': 30,\n",
       "  'prompt': 'Leonardo Balada found employment in',\n",
       "  'target_new': 'Paris',\n",
       "  'subject': 'Leonardo Balada',\n",
       "  'ground_truth': 'Pittsburgh',\n",
       "  'rephrase_prompt': 'To get to work every day, Leonardo Balada has to',\n",
       "  'locality_prompt': 'Pierre Bonnard used to work in',\n",
       "  'locality_ground_truth': 'Pittsburgh',\n",
       "  'sbj_hop_train': ['Generación del 51',\n",
       "   'Carnegie Mellon University',\n",
       "   'Pittsburgh',\n",
       "   'librettist',\n",
       "   'musicologist'],\n",
       "  'sbj_hop_test': ['Sant Just Desvern',\n",
       "   'sardana',\n",
       "   'symphony',\n",
       "   'Catalan',\n",
       "   'Barcelona'],\n",
       "  'obj_true_hop_train': ['Misgav Regional Council',\n",
       "   'Allegheny County',\n",
       "   'Ōmiya',\n",
       "   'Novokuznetsk',\n",
       "   ' 1st Earl of Chatham'],\n",
       "  'obj_true_hop_test': ['Naucalpan de Juárez delegation',\n",
       "   'San Isidro',\n",
       "   'Saitama',\n",
       "   'William Pitt',\n",
       "   'Prešov'],\n",
       "  'obj_new_hop_train': ['Parisii',\n",
       "   'Grand Paris',\n",
       "   'C40 Cities Climate Leadership Group',\n",
       "   'League of Historical Cities',\n",
       "   'Europe'],\n",
       "  'obj_new_hop_test': ['arrondissement of Paris',\n",
       "   'Île-de-France',\n",
       "   'Kingdom of France',\n",
       "   'World Tourism Cities Federation',\n",
       "   'Rome']},\n",
       " {'case_id': 34,\n",
       "  'prompt': 'Laurent Cars was employed in',\n",
       "  'target_new': 'Philadelphia',\n",
       "  'subject': 'Laurent Cars',\n",
       "  'ground_truth': 'Paris',\n",
       "  'rephrase_prompt': \"Laurent Cars's work office is surrounded by\",\n",
       "  'locality_prompt': 'Henri Matisse used to work in',\n",
       "  'locality_ground_truth': 'Paris',\n",
       "  'sbj_hop_train': ['Académie royale de peinture et de sculpture',\n",
       "   'printer',\n",
       "   'Lyon',\n",
       "   'painter',\n",
       "   'France'],\n",
       "  'sbj_hop_test': ['copper engraver', 'portrait', 'drawer', 'Paris', 'French'],\n",
       "  'obj_true_hop_train': ['Parisii',\n",
       "   'Grand Paris',\n",
       "   'C40 Cities Climate Leadership Group',\n",
       "   'League of Historical Cities',\n",
       "   'Europe'],\n",
       "  'obj_true_hop_test': ['arrondissement of Paris',\n",
       "   'Île-de-France',\n",
       "   'Kingdom of France',\n",
       "   'World Tourism Cities Federation',\n",
       "   'Rome'],\n",
       "  'obj_new_hop_train': ['Mosul',\n",
       "   'Philadelphia County',\n",
       "   'Douala',\n",
       "   'Kobe',\n",
       "   'Salvador'],\n",
       "  'obj_new_hop_test': ['Abruzzo',\n",
       "   'Nizhny Novgorod',\n",
       "   'Aix-en-Provence',\n",
       "   'Toruń',\n",
       "   'Tianjin']}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('counterfact-hop10.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(answer, json_file, ensure_ascii=False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
